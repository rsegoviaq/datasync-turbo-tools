# s5cmd Configuration Template
#
# Copy this file to s5cmd.env and customize for your environment:
#   cp config/s5cmd.env.template config/s5cmd.env
#   nano config/s5cmd.env
#
# Usage:
#   ./scripts/datasync-s5cmd.sh
#

# =============================================================================
# UPLOAD-ONLY SYNC DESIGN
# =============================================================================
# This configuration is designed for UPLOAD-ONLY synchronization:
# - Only uploads new/modified files to S3
# - NEVER deletes files from S3 (no --delete flag)
# - Safe to run even with empty source directory
#
# Destination data remains protected regardless of source state.
# =============================================================================

# ============================================
# Required Settings
# ============================================

# Local source directory to upload
SOURCE_DIR="/path/to/source/directory"

# S3 bucket name (without s3:// prefix)
S3_BUCKET="your-bucket-name"

# S3 subdirectory/prefix (optional, leave empty for bucket root)
S3_SUBDIRECTORY="optional/prefix/path"

# ============================================
# AWS Configuration
# ============================================

# AWS profile to use (optional, uses default if not set)
# AWS_PROFILE="default"

# AWS region (REQUIRED for s5cmd - must be set explicitly)
# s5cmd requires AWS_REGION as environment variable even when using profiles
AWS_REGION="us-east-1"

# ============================================
# s5cmd Performance Settings
# ============================================

# Number of parallel file operations
# Higher values = faster uploads but more memory/CPU usage
# Recommended: 32-128 depending on network and system resources
# Default: 64
S5CMD_CONCURRENCY="64"

# Multipart upload chunk size
# Larger chunks = fewer API calls but more memory per chunk
# Recommended: 32MB-128MB for files > 100MB
# Default: 64MB
S5CMD_PART_SIZE="64MB"

# Number of worker goroutines for processing operations
# Higher values = more concurrent processing
# Recommended: 16-64 depending on CPU cores
# Default: 32
S5CMD_NUM_WORKERS="32"

# Number of retry attempts for failed operations
# Recommended: 3-5 for unstable networks
# Default: 3
S5CMD_RETRY_COUNT="3"

# ============================================
# Data Integrity Settings
# ============================================

# Checksum algorithm for data verification
# Options:
#   CRC64NVME - Hardware-accelerated, fastest (recommended)
#   SHA256    - More robust, slower, required for some compliance
#   none      - No checksum verification (not recommended)
# Default: CRC64NVME
S5CMD_CHECKSUM="CRC64NVME"

# ============================================
# S3 Storage Settings
# ============================================

# S3 storage class
# Options:
#   STANDARD              - General purpose, frequent access
#   STANDARD_IA           - Infrequent access, lower cost
#   INTELLIGENT_TIERING   - Automatic cost optimization (recommended)
#   ONEZONE_IA           - Single AZ, infrequent access
#   GLACIER_IR           - Archive with instant retrieval
#   GLACIER              - Archive with 3-5 hour retrieval
#   DEEP_ARCHIVE         - Lowest cost, 12 hour retrieval
# Default: INTELLIGENT_TIERING
S3_STORAGE_CLASS="INTELLIGENT_TIERING"

# ============================================
# Logging Settings
# ============================================

# Log level for s5cmd operations
# Options: debug, info, warn, error
# Default: info
S5CMD_LOG_LEVEL="info"

# ============================================
# Advanced Settings (Optional)
# ============================================

# Maximum bandwidth in MB/s (optional, unlimited if not set)
# Useful for limiting network usage during business hours
# S5CMD_BANDWIDTH_LIMIT="100"

# Exclude patterns (space-separated, optional)
# Example: "*.tmp *.log .git/*"
# S5CMD_EXCLUDE_PATTERNS=""

# Include only patterns (space-separated, optional)
# Example: "*.jpg *.png *.mp4"
# S5CMD_INCLUDE_PATTERNS=""

# ============================================
# Performance Tuning Guide
# ============================================
#
# For 1 Gbps networks (125 MB/s):
#   S5CMD_CONCURRENCY="32"
#   S5CMD_NUM_WORKERS="16"
#   S5CMD_PART_SIZE="32MB"
#   Expected throughput: 100-120 MB/s
#
# For 3 Gbps networks (375 MB/s):
#   S5CMD_CONCURRENCY="64"
#   S5CMD_NUM_WORKERS="32"
#   S5CMD_PART_SIZE="64MB"
#   Expected throughput: 300-350 MB/s
#
# For 10 Gbps networks (1250 MB/s):
#   S5CMD_CONCURRENCY="128"
#   S5CMD_NUM_WORKERS="64"
#   S5CMD_PART_SIZE="128MB"
#   Expected throughput: 800-1200 MB/s
#
# For systems with limited CPU/memory:
#   S5CMD_CONCURRENCY="16"
#   S5CMD_NUM_WORKERS="8"
#   S5CMD_PART_SIZE="32MB"
#
# For maximum reliability (slower but safer):
#   S5CMD_CONCURRENCY="16"
#   S5CMD_RETRY_COUNT="5"
#   S5CMD_CHECKSUM="SHA256"
#
# ============================================
# Compatibility Notes
# ============================================
#
# This configuration file is compatible with datasync-simulator.sh
# environment variables. You can use the same config file for both
# tools by adding s5cmd-specific variables to your existing config.
#
# Shared variables:
#   - SOURCE_DIR
#   - S3_BUCKET
#   - S3_SUBDIRECTORY
#   - AWS_PROFILE
#   - AWS_REGION
#   - S3_STORAGE_CLASS
#
# s5cmd-specific variables (ignored by AWS CLI):
#   - S5CMD_CONCURRENCY
#   - S5CMD_PART_SIZE
#   - S5CMD_NUM_WORKERS
#   - S5CMD_RETRY_COUNT
#   - S5CMD_CHECKSUM
#   - S5CMD_LOG_LEVEL
#
